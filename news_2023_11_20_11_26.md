# news_2023_11_20_11_26

- https://gpuopen.com/learn/how_do_you_become_a_graphics_programmer/
  How do I become a graphics programmer? - A small guide from the AMD Game Engineering team

- https://ln.hixie.ch/?start=1700627373
- https://news.ycombinator.com/item?id=38381573
  Reflecting on 18 years at Google

- http://arxiv.org/abs/2311.10770
- https://arxiv.org/abs/2308.14711
- https://news.ycombinator.com/item?id=38364084
- https://huggingface.co/pbelcak/UltraFastBERT-1x11-long
- https://github.com/pbelcak/UltraFastBERT
  Exponentially faster language modelling

- https://www.youtube.com/watch?v=SEwTjZvy8vw
  2023 LLVM Dev Mtg - Mojo 🔥: A system programming language for heterogenous computing
  TODO: Mojo + AI in http://mlforsystems.org/

- https://github.com/e2b-dev/awesome-ai-agents
  🔮 Awesome AI Agents

- https://www.v2ex.com/t/994243
  如何参与开源项目？

  ```
  很难，你不是项目核心成员就没法参与核心需求的设计实现，最多就是一些修修补补的工作，要是你一厢情愿提交一些你觉得比较重要的需求实现，很容易就被驳回了，最后也是徒劳。我目前工作就是基于一个开源的项目做扩展，先是有了组里给的真实需求，然后再去设计实现，感觉这样才真的能参与进去。
  ```

- https://sms-activate.org/cn/rent
  虚拟号码出租

- https://discourse.llvm.org/t/mlir-clarifications-about-memrefs-vectors-tensors/2412
- https://groups.google.com/a/tensorflow.org/g/mlir/c/ezFbiShL6ow
  [MLIR] Clarifications about memrefs / vectors / tensors

- https://lmsys.org/blog/2023-11-21-lookahead-decoding/
  Break the Sequential Dependency of LLM Inference Using Lookahead Decoding

- https://www.qualcomm.com/news/onq/2023/11/introducing-qualcomm-cloud-ai-100-ultra
  Introducing Qualcomm Cloud AI 100 Ultra

- https://www.huxiu.com/article/2294867.html
  中国大模型创业公司，学不起 OpenAI
  "更适合中国市场和环境的新 AI 创业公司" ?

- https://news.ycombinator.com/item?id=37154395
  MLIR For Beginners: A series of articles on the MLIR framework

- https://news.ycombinator.com/item?id=35791205
  Building a Compiler with Multi-Level Intermediate Representation (MLIR)

  ```
  MLIR in its structure and textual syntax is a bit different. A "dialect" is more like a namespace for your ops than a different language, in my view.
  ```

- https://news.ycombinator.com/item?id=36538344
  Ask HN: LLVM vs. C?

- https://www.anandtech.com/show/16725/amd-demonstrates-stacked-vcache-technology-2-tbsec-for-15-gaming
- https://zhuanlan.zhihu.com/p/457128292
  AMD Demonstrates Stacked 3D V-Cache Technology: 192 MB at 2 TB/sec

- https://fabiensanglard.net/dc/index.php
- https://fabiensanglard.net/dc/driver.php
- https://fabiensanglard.net/dc/cpp.php
- https://fabiensanglard.net/dc/cc.php
- https://fabiensanglard.net/dc/ld.php
- https://fabiensanglard.net/dc/loader.php
- https://news.ycombinator.com/item?id=35806237
  Driving Compilers

- https://fabiensanglard.net/
- https://fabiensanglard.net/40/
- https://fabiensanglard.net/blog/
- https://fabiensanglard.net/algorithms_and_datastructures/index.php
  Fabien Sanglard's Website
  good blog

- https://huaren.us/showtopic.html?topicid=2725360&fid=398
  大家阅读中文的速度是英文的几倍
- https://groups.google.com/g/pongba/c/ZgGLBFcXS1k
  {OT}为什么读了三四年的英文，阅读速度仍然比不上阅读中文？
- https://www.utc.edu/enrollment-management-and-student-affairs/center-for-academic-support-and-advisement/tips-for-academic-success/skimming
- https://zhuanlan.zhihu.com/p/411457309
  "skimming"

- https://www.1point3acres.com/bbs/thread-1027664-1-1.html
  [职场感言]如何转去 LLM modeling 领域？

  ```
  毫无疑问大模型的核心就在于模型建模的核心在于三块：
  -a) 高质量数据data
  -b) 大机群训练infra
  -c) 模型架构和调参数train

  普通人(务实的角度), 做 b
  ```

- http://graphics.stanford.edu/~seander/bithacks.html
  Bit Twiddling Hacks
  TODO
